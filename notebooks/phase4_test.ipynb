{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b187a7fe-e025-4979-8b4c-0bb65bfbd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üîπ Cell 1 ‚Äî Imports & Setup\n",
    "# import torch\n",
    "# import sys\n",
    "# import os\n",
    "# sys.path.append(\"..\")\n",
    "\n",
    "# from src.schema_parser import SchemaParser\n",
    "# from src.nl_parser import NLParser\n",
    "# from src.semantic_aligner import SemanticAligner\n",
    "# from src.schema_binder import bind_schema_tokens\n",
    "# from src.ast_adapter import adapt_token_ast\n",
    "# from src.ast_renderer import SQLRenderer\n",
    "# from src.where_parser import WhereParser\n",
    "\n",
    "\n",
    "# from src.utils import (\n",
    "#     tokens_to_ids,\n",
    "#     ids_to_tokens,\n",
    "\n",
    "#     create_attention_mask,\n",
    "#     get_device,\n",
    "#     get_allowed_tokens  # üî• Ensure this is the updated version\n",
    "# )\n",
    "\n",
    "# from src.vocab import START, PAD, TOKEN2ID, ID2TOKEN, tokens_to_ast, AGG, VALUE,OPS\n",
    "# from models.sql_transformer import SQLTransformer\n",
    "\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.schema_parser import SchemaParser\n",
    "from src.nl_parser import NLParser\n",
    "from src.semantic_aligner import SemanticAligner\n",
    "from src.schema_binder import bind_schema_tokens\n",
    "from src.ast_adapter import adapt_token_ast\n",
    "from src.ast_renderer import SQLRenderer\n",
    "from src.where_parser import WhereParser\n",
    "from src.phase2_inference import infer_phase2_sql\n",
    "from src.phase3_inference import infer_phase3_sql\n",
    "\n",
    "from src.utils import (\n",
    "    tokens_to_ids,\n",
    "    ids_to_tokens,\n",
    "    create_attention_mask,\n",
    "    get_device,\n",
    "    get_allowed_tokens\n",
    ")\n",
    "\n",
    "from src.vocab import START, PAD, TOKEN2ID, ID2TOKEN, tokens_to_ast\n",
    "from models.sql_transformer import SQLTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4022dd1-8a89-489b-ac06-6fbc4f67b6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Phase-4 JOIN model loaded (Backward Compatible)\n"
     ]
    }
   ],
   "source": [
    "# # üîπ Cell 2 ‚Äî Load Phase-4 JOIN Model\n",
    "# device = get_device()\n",
    "# model = SQLTransformer().to(device)\n",
    "\n",
    "# # ‚úÖ PHASE-4 LOADING SURGERY\n",
    "# PHASE4_CKPT = \"checkpoints/phase4_model.pt\"\n",
    "# checkpoint_state = torch.load(PHASE4_CKPT, map_location=device)\n",
    "# model_state = model.state_dict()\n",
    "\n",
    "# # Map old weights to new model indices (0-47)\n",
    "# mismatched_layers = [\"embedding.weight\", \"fc_out.weight\", \"fc_out.bias\"]\n",
    "# for name, param in checkpoint_state.items():\n",
    "#     if name in mismatched_layers:\n",
    "#         if len(param.shape) > 1:\n",
    "#             model_state[name][:param.shape[0], :] = param\n",
    "#         else:\n",
    "#             model_state[name][:param.shape[0]] = param\n",
    "#     else:\n",
    "#         model_state[name] = param\n",
    "\n",
    "# model.load_state_dict(model_state)\n",
    "# model.eval()\n",
    "# print(\"‚úÖ Phase-4 JOIN model loaded with Surgery (Size 49)\")\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "model = SQLTransformer().to(device)\n",
    "\n",
    "PHASE4_CKPT = \"checkpoints/phase4_model.pt\"\n",
    "checkpoint_state = torch.load(PHASE4_CKPT, map_location=device)\n",
    "model_state = model.state_dict()\n",
    "\n",
    "mismatched_layers = [\"embedding.weight\", \"fc_out.weight\", \"fc_out.bias\"]\n",
    "\n",
    "for name, param in checkpoint_state.items():\n",
    "    if name in mismatched_layers:\n",
    "        if len(param.shape) > 1:\n",
    "            model_state[name][:param.shape[0], :] = param\n",
    "        else:\n",
    "            model_state[name][:param.shape[0]] = param\n",
    "    else:\n",
    "        model_state[name] = param\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "print(\"‚úÖ Phase-4 JOIN model loaded (Backward Compatible)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48804541-e15b-43a2-a9d4-d78351ac110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Cell 3 ‚Äî User Schema (Relationships preserved)\n",
    "USER_SCHEMA = {\n",
    "    \"schema_id\": \"U1\",\n",
    "    \"tables\": {\n",
    "        \"employees\": [\"emp_id\", \"first_name\", \"dept_id\", \"salary\",\"location\"],\n",
    "        \"departments\": [\"dept_id\", \"dept_name\", \"manager_id\"],\n",
    "        \"orders\": [\"order_id\", \"customer_id\", \"total_amount\"],\n",
    "        \"customers\": [\"customer_id\", \"last_name\", \"country\"]\n",
    "    }\n",
    "    \n",
    "}\n",
    "#show last_name and order total_amount from customers and orders\n",
    "#show first_name and dept_name from employees and departments where dept_name is ai and manager_id is 123\n",
    "#list last_name and total_amount from customers and orders where total_amount is greater than 500\n",
    "#show average salary from employees\n",
    "# get dept_id, dept_name from departments\n",
    "#get dept_name from departments where dept_id = 123\n",
    "#show average salary from employees by dept_id and location\n",
    "USER_NL_QUERY = \"get dept_id, dept_name from departments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "698902b1-8ebe-40ea-8904-1dc36f37bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üîπ Cell 4\n",
    "# def discover_relationships(schema_tables):\n",
    "#     \"\"\"\n",
    "#     Automatically finds Primary-Foreign key pairs by matching column names.\n",
    "#     Strategy: If 'dept_id' exists in Table A and Table B, they are related.\n",
    "#     \"\"\"\n",
    "#     relationships = []\n",
    "#     table_names = list(schema_tables.keys())\n",
    "    \n",
    "#     for i in range(len(table_names)):\n",
    "#         for j in range(i + 1, len(table_names)):\n",
    "#             t1, t2 = table_names[i], table_names[j]\n",
    "#             cols1 = set(schema_tables[t1])\n",
    "#             cols2 = set(schema_tables[t2])\n",
    "            \n",
    "#             # Find common columns (e.g., {'dept_id'})\n",
    "#             common = cols1.intersection(cols2)\n",
    "            \n",
    "#             # Filter out generic names like 'id' or 'name' to avoid false positives\n",
    "#             for col in common:\n",
    "#                 if col.lower() not in [\"id\", \"name\", \"created_at\", \"updated_at\"]:\n",
    "#                     relationships.append({\n",
    "#                         \"from\": f\"{t1}.{col}\",\n",
    "#                         \"to\": f\"{t2}.{col}\"\n",
    "#                     })\n",
    "#     return relationships\n",
    "\n",
    "\n",
    "def discover_relationships(schema_tables):\n",
    "    relationships = []\n",
    "    table_names = list(schema_tables.keys())\n",
    "\n",
    "    for i in range(len(table_names)):\n",
    "        for j in range(i + 1, len(table_names)):\n",
    "            t1, t2 = table_names[i], table_names[j]\n",
    "            cols1 = set(schema_tables[t1])\n",
    "            cols2 = set(schema_tables[t2])\n",
    "\n",
    "            common = cols1.intersection(cols2)\n",
    "\n",
    "            for col in common:\n",
    "                if col.lower() not in {\"id\", \"name\", \"created_at\", \"updated_at\"}:\n",
    "                    relationships.append({\n",
    "                        \"left_table\": t1,\n",
    "                        \"right_table\": t2,\n",
    "                        \"left_col\": col,\n",
    "                        \"right_col\": col\n",
    "                    })\n",
    "    return relationships\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "936bb7e9-6357-4870-a566-58561fab251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üîπ Cell 5\n",
    "# def infer_phase4_sql(schema_json, nl_query):\n",
    "#     # 1Ô∏è‚É£ Setup\n",
    "#     schema_parser = SchemaParser(schema_json)\n",
    "#     all_columns = schema_parser.get_all_columns()\n",
    "#     tables_dict = schema_json[\"tables\"]\n",
    "#     auto_rels = discover_relationships(tables_dict)\n",
    "    \n",
    "#     nl_parser = NLParser()\n",
    "#     signals = nl_parser.parse(nl_query)\n",
    "#     nl_lower = nl_query.lower()\n",
    "\n",
    "#     # 2Ô∏è‚É£ Transformer structural decoding\n",
    "#     prompt_ids = tokens_to_ids([START])\n",
    "#     input_ids = torch.tensor([prompt_ids], device=device)\n",
    "#     attention_mask = torch.ones(input_ids.shape, device=device)\n",
    "    \n",
    "#     generated_ids = model.generate(\n",
    "#         input_ids=input_ids,\n",
    "#         attention_mask=attention_mask,\n",
    "#         schema_tables=schema_parser.get_tables(),\n",
    "#         schema_columns=all_columns,\n",
    "#         intent_signals=signals # Signals 'where': True [cite: 147-148]\n",
    "#     )\n",
    "#     tokens = ids_to_tokens(generated_ids)\n",
    "\n",
    "#     # 3Ô∏è‚É£ JOIN bridge Resolution\n",
    "#     resolved_tables = [t for t in signals[\"tables\"] if t in tables_dict]\n",
    "#     join_columns = []\n",
    "#     if len(resolved_tables) >= 2:\n",
    "#         for rel in auto_rels:\n",
    "#             t1, t2 = rel[\"from\"].split('.')[0], rel[\"to\"].split('.')[0]\n",
    "#             if t1 in resolved_tables and t2 in resolved_tables:\n",
    "#                 join_columns = [rel[\"from\"], rel[\"to\"]]\n",
    "#                 break\n",
    "\n",
    "#     # 4Ô∏è‚É£ Recursive Boolean WHERE Logic üî•\n",
    "#     where_ast = None\n",
    "#     if \"WHERE\" in tokens and \"where\" in nl_lower:\n",
    "#         where_text = nl_lower.split(\"where\", 1)[1]\n",
    "#         aligner = SemanticAligner()\n",
    "#         where_parser = WhereParser(nl_parser, aligner)\n",
    "        \n",
    "#         # Tokenize into [dept_name is ai, and, manager_id is 123]\n",
    "#         wp_tokens = where_parser.tokenize(where_text)\n",
    "#         where_ast = where_parser.build_tree(\n",
    "#             wp_tokens, \n",
    "#             table=resolved_tables[0], \n",
    "#             table_cols=tables_dict[resolved_tables[0]], \n",
    "#             all_columns=all_columns \n",
    "#         )\n",
    "\n",
    "#     # 5Ô∏è‚É£ Final Binding & SELECT Alignment\n",
    "#     aligner = SemanticAligner()\n",
    "#     mapping = aligner.align(user_terms=signals[\"entities\"], schema_terms=all_columns)\n",
    "#     select_cols = list(dict.fromkeys([mapping[e] for e in signals[\"entities\"] if e in mapping]))\n",
    "\n",
    "#     schema_bindings = {\n",
    "#         \"<TABLE>\": resolved_tables,\n",
    "#         \"<COLUMN>\": {\n",
    "#             \"select\": select_cols,\n",
    "#             \"join_left\": join_columns[0] if join_columns else None,\n",
    "#             \"join_right\": join_columns[1] if join_columns else None,\n",
    "#             \"where\": [] # Handled by where_ast\n",
    "#         },\n",
    "#         \"<VALUE>\": signals.get(\"value\")\n",
    "#     }\n",
    "\n",
    "#     bound_tokens = bind_schema_tokens(tokens, schema_bindings)\n",
    "#     bound_ast = tokens_to_ast(bound_tokens)\n",
    "    \n",
    "#     # Inject high-precision results\n",
    "#     bound_ast[\"select\"] = [{\"agg\": None, \"column\": col} for col in select_cols[:2]]\n",
    "#     if where_ast:\n",
    "#         bound_ast[\"where\"] = where_ast # Recursively renders AND/OR [cite: 37-39]\n",
    "\n",
    "#     return SQLRenderer().render(adapt_token_ast(bound_ast))\n",
    "\n",
    "\n",
    "def infer_phase4_sql(schema_json, nl_query):\n",
    "    schema_parser = SchemaParser(schema_json)\n",
    "    schema_tables = schema_parser.get_tables()\n",
    "    all_columns = schema_parser.get_all_columns()\n",
    "\n",
    "    nl_parser = NLParser()\n",
    "    signals = nl_parser.parse(nl_query)\n",
    "    nl_lower = nl_query.lower()\n",
    "\n",
    "    # Projection text = part before FROM\n",
    "    projection_text = nl_lower.split(\" from \", 1)[0]\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # üîë SCHEMA-AWARE TABLE RESOLUTION (IMPORTANT)\n",
    "    # ==================================================\n",
    "    resolved_tables = [\n",
    "        t for t in signals[\"entities\"]\n",
    "        if t in schema_tables\n",
    "    ]\n",
    "\n",
    "    print(\"shit1\")\n",
    "    # ==================================================\n",
    "    # üîÄ PHASE ROUTING (FINAL, CORRECT)\n",
    "    # ==================================================\n",
    "    if len(resolved_tables) >= 2:\n",
    "        pass  # Phase-4 JOIN (aggregation allowed)\n",
    "    elif (\n",
    "        signals[\"aggregations\"]\n",
    "        or signals.get(\"group_by\")\n",
    "        or signals.get(\"having\")\n",
    "    ):\n",
    "        return infer_phase3_sql(schema_json, nl_query)\n",
    "    else:\n",
    "        return infer_phase2_sql(schema_json, nl_query)\n",
    "\n",
    "    print(\"shit2\")\n",
    "    # ==================================================\n",
    "    # üß† PHASE-4 JOIN LOGIC\n",
    "    # ==================================================\n",
    "    auto_rels = discover_relationships(schema_json[\"tables\"])\n",
    "\n",
    "    # Transformer decode\n",
    "    input_ids = torch.tensor(\n",
    "        [tokens_to_ids([START])],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=torch.tensor(\n",
    "            [create_attention_mask(input_ids[0].tolist(), PAD)],\n",
    "            device=device\n",
    "        ),\n",
    "        schema_tables=schema_tables,\n",
    "        schema_columns=all_columns,\n",
    "        intent_signals=signals\n",
    "    )\n",
    "\n",
    "    # ==================================================\n",
    "    # üîó JOIN RESOLUTION\n",
    "    # ==================================================\n",
    "    join_pair = None\n",
    "    for rel in auto_rels:\n",
    "        if (\n",
    "            rel[\"left_table\"] in resolved_tables\n",
    "            and rel[\"right_table\"] in resolved_tables\n",
    "        ):\n",
    "            join_pair = rel\n",
    "            break\n",
    "\n",
    "    if not join_pair:\n",
    "        raise ValueError(\"‚ùå Could not resolve JOIN relationship\")\n",
    "\n",
    "    # ==================================================\n",
    "    # üéØ SELECT ALIGNMENT (FINAL, STRICT)\n",
    "    # ==================================================\n",
    "    aligner = SemanticAligner()\n",
    "    mapping = aligner.align(\n",
    "        user_terms=signals[\"entities\"],\n",
    "        schema_terms=all_columns\n",
    "    )\n",
    "    \n",
    "    select_cols = []\n",
    "    \n",
    "    for term in signals[\"entities\"]:\n",
    "        # must look like a column\n",
    "        if \"_\" in term:\n",
    "            # must appear in projection part (before FROM)\n",
    "            if term in projection_text:\n",
    "                if term in mapping:\n",
    "                    mapped = mapping[term]\n",
    "                    if \".\" in mapped:\n",
    "                        select_cols.append(mapped)\n",
    "    \n",
    "    # Deduplicate, preserve order\n",
    "    select_cols = list(dict.fromkeys(select_cols))\n",
    "\n",
    "\n",
    "\n",
    "    base_table = resolved_tables[0]\n",
    "\n",
    "    # ==================================================\n",
    "    # üîé WHERE (Safe handling)\n",
    "    # ==================================================\n",
    "    where_ast = None\n",
    "    \n",
    "    if \" where \" in nl_lower:\n",
    "        where_text = nl_lower.split(\" where \", 1)[1]\n",
    "    \n",
    "        where_parser = WhereParser(nl_parser, aligner)\n",
    "    \n",
    "        wp_tokens = where_parser.tokenize(where_text)\n",
    "    \n",
    "        where_ast = where_parser.build_tree(\n",
    "            wp_tokens,\n",
    "            table=base_table,\n",
    "            table_cols=schema_json[\"tables\"][base_table],\n",
    "            all_columns=all_columns\n",
    "        )\n",
    "\n",
    "\n",
    "    # ==================================================\n",
    "    # üß© AST\n",
    "    # ==================================================\n",
    "    \n",
    "\n",
    "    bound_ast = {\n",
    "        \"select\": [\n",
    "            {\"agg\": None, \"column\": c}\n",
    "            for c in select_cols\n",
    "        ],\n",
    "    \n",
    "        \"from\": [base_table],\n",
    "    \n",
    "        \"joins\": [\n",
    "            {\n",
    "                \"type\": \"INNER\",\n",
    "                \"table\": join_pair[\"right_table\"]\n",
    "                if join_pair[\"left_table\"] == base_table\n",
    "                else join_pair[\"left_table\"],\n",
    "                \"on\": {\n",
    "                    \"left\": f\"{join_pair['left_table']}.{join_pair['left_col']}\",\n",
    "                    \"op\": \"=\",\n",
    "                    \"right\": f\"{join_pair['right_table']}.{join_pair['right_col']}\",\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "    \n",
    "        \"where\": where_ast or []\n",
    "    }\n",
    "\n",
    "\n",
    "    return SQLRenderer().render(bound_ast)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9eb061f-b708-4dd9-b485-5bed50511cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shit1\n",
      "üß† NL Query : get dept_id, dept_name from departments\n",
      "üßæ SQL Query: SELECT departments.dept_id, departments.dept_name FROM departments\n"
     ]
    }
   ],
   "source": [
    "# #  üîπ Cell 6 - Run Inference\n",
    "# #try:\n",
    "# sql_output = infer_phase4_sql(USER_SCHEMA, USER_NL_QUERY)\n",
    "# print(\"üß† NL Query :\", USER_NL_QUERY)\n",
    "# print(\"üßæ SQL Query:\", sql_output)\n",
    "# #except Exception as e:\n",
    "#     #print(f\"‚ùå Inference Error: {e}\")\n",
    "\n",
    "sql_output = infer_phase4_sql(USER_SCHEMA, USER_NL_QUERY)\n",
    "\n",
    "print(\"üß† NL Query :\", USER_NL_QUERY)\n",
    "print(\"üßæ SQL Query:\", sql_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e6d24d-fa30-45ad-96de-6ab90319c5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae53308f-fe5a-4082-96fb-5bbcf6d2ec51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeff2db-78c1-4352-a399-8049e2cc8d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
