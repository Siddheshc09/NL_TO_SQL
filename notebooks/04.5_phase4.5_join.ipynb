{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ea25567-20ae-4666-a12a-5672e43e85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ Cell 1 â€” Imports & Config (Phase-4.5 JOIN)\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from src.utils import (\n",
    "    tokens_to_ids,\n",
    "    pad_sequence,\n",
    "    create_attention_mask,\n",
    "    get_allowed_tokens\n",
    ")\n",
    "\n",
    "from src.vocab import PAD, TOKEN2ID, ID2TOKEN, UNK\n",
    "from models.sql_transformer import SQLTransformer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# âœ… CHECKPOINT PATH\n",
    "CHECKPOINT_DIR = \"notebooks/checkpoints/phase4_5_join\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2755165d-296c-445e-99cd-b6f9754dda81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Phase-4.5 samples: 2000\n"
     ]
    }
   ],
   "source": [
    "#ğŸ”¹ Cell 2 â€” Phase-4.5 Config\n",
    "PHASE3_CKPT = \"checkpoints/phase3_model.pt\"\n",
    "PHASE4_5_CKPT = \"checkpoints/phase4_5_model.pt\"\n",
    "\n",
    "PHASE4_5_PATH = \"../data/sql_ast/phase4.5_join.json\"\n",
    "\n",
    "with open(PHASE4_5_PATH, \"r\") as f:\n",
    "    phase4_5_data = json.load(f)\n",
    "\n",
    "print(\"Total Phase-4.5 samples:\", len(phase4_5_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3f2f06-71b3-48aa-bce5-89aed560f236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ğŸ”¹ Cell 3 â€” Decoder Training Sample Builder (UNCHANGED LOGIC)\n",
    "def prepare_phase4_5_sample(sample):\n",
    "    \"\"\"\n",
    "    Converts phase4.5_joins.json entry into decoder input / label pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = sample[\"input_tokens\"]\n",
    "\n",
    "    token_ids = [\n",
    "        TOKEN2ID.get(t, TOKEN2ID[UNK])\n",
    "        for t in tokens\n",
    "    ]\n",
    "\n",
    "    input_ids = torch.tensor(token_ids[:-1], dtype=torch.long)\n",
    "    labels = torch.tensor(token_ids[1:], dtype=torch.long)\n",
    "\n",
    "    labels[labels == TOKEN2ID[PAD]] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa699a0-d891-4170-849c-ae54893a2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ Cell 4 â€” Dataset\n",
    "class Phase45JoinDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return prepare_phase4_5_sample(self.data[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878b4e11-cf62-4abf-8185-7b2a6f0556d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ Cell 5 â€” Collate Function (PAD + MASK)\n",
    "def phase4_5_collate_fn(batch):\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "\n",
    "    max_len = max(x.size(0) for x in input_ids)\n",
    "\n",
    "    padded_inputs, padded_labels = [], []\n",
    "\n",
    "    for inp, lab in zip(input_ids, labels):\n",
    "        pad_len = max_len - inp.size(0)\n",
    "\n",
    "        padded_inputs.append(\n",
    "            torch.cat([\n",
    "                inp,\n",
    "                torch.full((pad_len,), TOKEN2ID[PAD], dtype=torch.long)\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        padded_labels.append(\n",
    "            torch.cat([\n",
    "                lab,\n",
    "                torch.full((pad_len,), -100, dtype=torch.long)\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.stack(padded_inputs),\n",
    "        \"labels\": torch.stack(padded_labels)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f890f98d-380e-4a5b-8a20-a6817c29c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ Cell 6 â€” DataLoader\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = Phase45JoinDataset(phase4_5_data)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=phase4_5_collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43ef57cd-e4dd-416f-8f87-1e69432493ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ğŸ”¹ Cell 7 â€” Grammar-Masked Loss (NO LOGIC CHANGE)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def phase4_5_loss(logits, input_ids, labels, allowed_token_fn):\n",
    "    B, T, V = logits.size()\n",
    "    mask = torch.zeros((B, T, V), device=logits.device)\n",
    "\n",
    "    for b in range(B):\n",
    "        for t in range(T):\n",
    "            if labels[b, t] == -100:\n",
    "                continue\n",
    "\n",
    "            ids = input_ids[b, :t+1].tolist()\n",
    "            tokens_so_far = [ID2TOKEN.get(i, UNK) for i in ids]\n",
    "\n",
    "            allowed = allowed_token_fn(\n",
    "                tokens_so_far=tokens_so_far,\n",
    "                schema_tables=None,\n",
    "                schema_columns=None,\n",
    "                intent_signals=None   # âœ… SAFE FOR PHASE-4.5\n",
    "            )\n",
    "\n",
    "            if allowed:\n",
    "                m = torch.full((V,), -500.0, device=logits.device)\n",
    "                for tid in allowed:\n",
    "                    if tid < V:\n",
    "                        m[tid] = 0.0\n",
    "                mask[b, t, :] = m\n",
    "\n",
    "    masked_logits = logits + mask\n",
    "    loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "    return loss_fn(masked_logits.view(-1, V), labels.view(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d84f7b2-8a29-4cba-8fb4-35e9d260a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ Cell 8 â€” Metrics (UNCHANGED)\n",
    "def compute_prf(preds, labels, ignore_index=-100):\n",
    "    preds = preds.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "\n",
    "    mask = labels != ignore_index\n",
    "    preds = preds[mask]\n",
    "    labels = labels[mask]\n",
    "\n",
    "    tp = (preds == labels).sum().item()\n",
    "    fp = (preds != labels).sum().item()\n",
    "    fn = fp\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-9)\n",
    "    recall = tp / (tp + fn + 1e-9)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d41c7a-1d2d-49dc-b6e6-6c80b65cdf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Phase-3 â†’ Phase-4.5 vocab surgery complete\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ Cell 9 â€” Load Phase-3 Model (VOCAB SURGERY SAFE)\n",
    "model = SQLTransformer().to(device)\n",
    "\n",
    "checkpoint_state = torch.load(PHASE3_CKPT, map_location=device)\n",
    "model_state = model.state_dict()\n",
    "\n",
    "mismatched = [\"embedding.weight\", \"fc_out.weight\", \"fc_out.bias\"]\n",
    "\n",
    "for name, param in checkpoint_state.items():\n",
    "    if name in mismatched:\n",
    "        new_param = model_state[name]\n",
    "        if param.ndim > 1:\n",
    "            new_param[:param.size(0), :] = param\n",
    "        else:\n",
    "            new_param[:param.size(0)] = param\n",
    "        model_state[name] = new_param\n",
    "    else:\n",
    "        model_state[name] = param\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "\n",
    "print(\"âœ… Phase-3 â†’ Phase-4.5 vocab surgery complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30b1ef22-f2b6-4419-9c58-c748759418ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ğŸ”¹ Cell 10 â€” Grammar Sanity Check (OPTIONAL BUT SAFE)\n",
    "def verify_grammar_with_data(dataset, allowed_fn):\n",
    "    conflicts = 0\n",
    "    skipped = 0\n",
    "\n",
    "    for sample in dataset:\n",
    "        tokens = sample[\"input_tokens\"]\n",
    "\n",
    "        for t in range(len(tokens) - 1):\n",
    "            next_tok = tokens[t + 1]\n",
    "\n",
    "            # ğŸ”¥ SKIP tokens that are NOT part of model vocab\n",
    "            if next_tok not in TOKEN2ID:\n",
    "                skipped += 1\n",
    "                continue\n",
    "\n",
    "            allowed = allowed_fn(\n",
    "                tokens_so_far=tokens[:t+1],\n",
    "                schema_tables=None,\n",
    "                schema_columns=None,\n",
    "                intent_signals=None\n",
    "            )\n",
    "\n",
    "            if TOKEN2ID[next_tok] not in allowed:\n",
    "                conflicts += 1\n",
    "\n",
    "    print(f\"Grammar conflicts: {conflicts}\")\n",
    "    print(f\"Skipped non-learnable tokens: {skipped}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823870fc-0f29-43a0-9cfa-265875434849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”¹ Cell 11 â€” Freeze Strategy\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layers.1\" in name or \"layers.2\" in name or \"fc_out\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ab3d7d8-ceb4-4a89-992c-2c8c58c036e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ğŸ”¹ Cell 12 â€” Optimizer\n",
    "optimizer = AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=3e-4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00f776a2-953b-40ed-8c99-26eaf3c2129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 89.1644 | P: 0.6132 | F1: 0.6132\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_01.pt\n",
      "ğŸ† New best model saved (loss=89.1644)\n",
      "Epoch 02 | Loss: 87.3003 | P: 0.7056 | F1: 0.7056\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_02.pt\n",
      "ğŸ† New best model saved (loss=87.3003)\n",
      "Epoch 03 | Loss: 85.6037 | P: 0.6432 | F1: 0.6432\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_03.pt\n",
      "ğŸ† New best model saved (loss=85.6037)\n",
      "Epoch 04 | Loss: 83.8162 | P: 0.6025 | F1: 0.6025\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_04.pt\n",
      "ğŸ† New best model saved (loss=83.8162)\n",
      "Epoch 05 | Loss: 82.0875 | P: 0.5609 | F1: 0.5609\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_05.pt\n",
      "ğŸ† New best model saved (loss=82.0875)\n",
      "Epoch 06 | Loss: 80.3018 | P: 0.5272 | F1: 0.5272\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_06.pt\n",
      "ğŸ† New best model saved (loss=80.3018)\n",
      "Epoch 07 | Loss: 78.5093 | P: 0.5035 | F1: 0.5035\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_07.pt\n",
      "ğŸ† New best model saved (loss=78.5093)\n",
      "Epoch 08 | Loss: 76.7899 | P: 0.4920 | F1: 0.4920\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_08.pt\n",
      "ğŸ† New best model saved (loss=76.7899)\n",
      "Epoch 09 | Loss: 75.0455 | P: 0.4694 | F1: 0.4694\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_09.pt\n",
      "ğŸ† New best model saved (loss=75.0455)\n",
      "Epoch 10 | Loss: 73.2915 | P: 0.4592 | F1: 0.4592\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_10.pt\n",
      "ğŸ† New best model saved (loss=73.2915)\n",
      "Epoch 11 | Loss: 71.5177 | P: 0.4383 | F1: 0.4383\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_11.pt\n",
      "ğŸ† New best model saved (loss=71.5177)\n",
      "Epoch 12 | Loss: 69.7950 | P: 0.4144 | F1: 0.4144\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_12.pt\n",
      "ğŸ† New best model saved (loss=69.7950)\n",
      "Epoch 13 | Loss: 68.0765 | P: 0.3994 | F1: 0.3994\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_13.pt\n",
      "ğŸ† New best model saved (loss=68.0765)\n",
      "Epoch 14 | Loss: 66.3411 | P: 0.4097 | F1: 0.4097\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_14.pt\n",
      "ğŸ† New best model saved (loss=66.3411)\n",
      "Epoch 15 | Loss: 64.6131 | P: 0.4332 | F1: 0.4332\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_15.pt\n",
      "ğŸ† New best model saved (loss=64.6131)\n",
      "Epoch 16 | Loss: 62.8652 | P: 0.4365 | F1: 0.4365\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_16.pt\n",
      "ğŸ† New best model saved (loss=62.8652)\n",
      "Epoch 17 | Loss: 61.2026 | P: 0.4336 | F1: 0.4336\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_17.pt\n",
      "ğŸ† New best model saved (loss=61.2026)\n",
      "Epoch 18 | Loss: 59.4800 | P: 0.4273 | F1: 0.4273\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_18.pt\n",
      "ğŸ† New best model saved (loss=59.4800)\n",
      "Epoch 19 | Loss: 57.7996 | P: 0.4392 | F1: 0.4392\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_19.pt\n",
      "ğŸ† New best model saved (loss=57.7996)\n",
      "Epoch 20 | Loss: 56.1068 | P: 0.4326 | F1: 0.4326\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_20.pt\n",
      "ğŸ† New best model saved (loss=56.1068)\n",
      "Epoch 21 | Loss: 54.3890 | P: 0.4274 | F1: 0.4274\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_21.pt\n",
      "ğŸ† New best model saved (loss=54.3890)\n",
      "Epoch 22 | Loss: 52.6933 | P: 0.4196 | F1: 0.4196\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_22.pt\n",
      "ğŸ† New best model saved (loss=52.6933)\n",
      "Epoch 23 | Loss: 51.0255 | P: 0.4271 | F1: 0.4271\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_23.pt\n",
      "ğŸ† New best model saved (loss=51.0255)\n",
      "Epoch 24 | Loss: 49.3397 | P: 0.4207 | F1: 0.4207\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_24.pt\n",
      "ğŸ† New best model saved (loss=49.3397)\n",
      "Epoch 25 | Loss: 47.6572 | P: 0.4243 | F1: 0.4243\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_25.pt\n",
      "ğŸ† New best model saved (loss=47.6572)\n",
      "Epoch 26 | Loss: 46.0020 | P: 0.4218 | F1: 0.4218\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_26.pt\n",
      "ğŸ† New best model saved (loss=46.0020)\n",
      "Epoch 27 | Loss: 44.3227 | P: 0.4203 | F1: 0.4203\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_27.pt\n",
      "ğŸ† New best model saved (loss=44.3227)\n",
      "Epoch 28 | Loss: 42.6167 | P: 0.4060 | F1: 0.4060\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_28.pt\n",
      "ğŸ† New best model saved (loss=42.6167)\n",
      "Epoch 29 | Loss: 40.9337 | P: 0.4024 | F1: 0.4024\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_29.pt\n",
      "ğŸ† New best model saved (loss=40.9337)\n",
      "Epoch 30 | Loss: 39.3116 | P: 0.4100 | F1: 0.4100\n",
      "ğŸ’¾ Saved epoch checkpoint: notebooks/checkpoints/phase4_5_join\\phase4_5_epoch_30.pt\n",
      "ğŸ† New best model saved (loss=39.3116)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”¹ Cell 13 â€” Training Loop (Phase-4.5 with Checkpoints)\n",
    "EPOCHS = 30\n",
    "model.train()\n",
    "\n",
    "best_loss = float(\"inf\")  # ğŸ”¥ Track best model\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss, steps = 0.0, 0\n",
    "    total_p, total_f1 = 0.0, 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        logits = model(input_ids)\n",
    "        loss = phase4_5_loss(logits, input_ids, labels, get_allowed_tokens)\n",
    "\n",
    "        # Safety check\n",
    "        if torch.isnan(loss):\n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        p, _, f1 = compute_prf(preds, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_p += p\n",
    "        total_f1 += f1\n",
    "        steps += 1\n",
    "\n",
    "    # ----------------------------\n",
    "    # Epoch summary\n",
    "    # ----------------------------\n",
    "    avg_loss = total_loss / steps\n",
    "    avg_p = total_p / steps\n",
    "    avg_f1 = total_f1 / steps\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1:02d} | \"\n",
    "        f\"Loss: {avg_loss:.4f} | \"\n",
    "        f\"P: {avg_p:.4f} | \"\n",
    "        f\"F1: {avg_f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    # ----------------------------\n",
    "    # ğŸ”¥ SAVE CHECKPOINT (EVERY EPOCH)\n",
    "    # ----------------------------\n",
    "    epoch_ckpt_path = os.path.join(\n",
    "        CHECKPOINT_DIR,\n",
    "        f\"phase4_5_epoch_{epoch+1:02d}.pt\"\n",
    "    )\n",
    "\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"avg_loss\": avg_loss\n",
    "        },\n",
    "        epoch_ckpt_path\n",
    "    )\n",
    "\n",
    "    print(f\"ğŸ’¾ Saved epoch checkpoint: {epoch_ckpt_path}\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # ğŸ”¥ SAVE BEST MODEL\n",
    "    # ----------------------------\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "\n",
    "        best_ckpt_path = os.path.join(\n",
    "            CHECKPOINT_DIR,\n",
    "            \"phase4_5_best.pt\"\n",
    "        )\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"best_loss\": best_loss\n",
    "            },\n",
    "            best_ckpt_path\n",
    "        )\n",
    "\n",
    "        print(f\"ğŸ† New best model saved (loss={best_loss:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32337b-df74-4b32-ac3f-b6432e149d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
