{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83576c8e-0b47-4720-b32d-874b02b5da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# üîπ Cell 1 ‚Äî Imports & Config (Phase-4 JOIN)\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from src.utils import (\n",
    "\n",
    "    tokens_to_ids,\n",
    "    pad_sequence,\n",
    "    create_attention_mask,\n",
    "    get_allowed_tokens\n",
    ")\n",
    "\n",
    "from src.vocab import PAD, TOKEN2ID, ID2TOKEN, UNK\n",
    "from models.sql_transformer import SQLTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba1325b-f247-41de-88dd-333fedd990e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da72d01b-f55c-4932-878c-6dbbe244cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ CHECKPOINT PATH (as per your folder structure)\n",
    "CHECKPOINT_DIR = \"notebooks/checkpoints/phase4_join\"\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9cea33-e0e8-4112-9d00-34d57246e31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Phase-4 samples: 2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# üîπ Cell 2 ‚Äî Phase-4 Config\n",
    "# =========================\n",
    "# CONFIG ‚Äî PHASE 4 (JOIN)\n",
    "# =========================\n",
    "\n",
    "PHASE3_CKPT = \"checkpoints/phase3_model.pt\"\n",
    "PHASE4_CKPT = \"checkpoints/phase4_model.pt\"\n",
    "\n",
    "PHASE4_PATH = \"../data/sql_ast/phase4_join.json\"\n",
    "\n",
    "with open(PHASE4_PATH, \"r\") as f:\n",
    "    phase4_data = json.load(f)\n",
    "\n",
    "print(\"Total Phase-4 samples:\", len(phase4_data))\n",
    "\n",
    "#EPOCHS = 30\n",
    "#BATCH_SIZE = 16\n",
    "#LR = 3e-4\n",
    "\n",
    "# JOIN adds: JOIN TABLE ON COL COL\n",
    "#MAX_LEN = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82ad19f2-f32d-433d-92a4-8aef63e94a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Cell 3 ‚Äî Decoder Training Sample Builder (Phase-4)\n",
    "\n",
    "def prepare_phase4_sample(sample):\n",
    "    \"\"\"\n",
    "    Converts phase4_join.json entry into decoder input / label pairs.\n",
    "    \n",
    "    Fixes:\n",
    "    ‚úî Proper teacher forcing (shifted labels)\n",
    "    ‚úî PAD tokens masked with -100 (ignored by loss & metrics)\n",
    "    ‚úî Safe TOKEN2ID lookup\n",
    "    \"\"\"\n",
    "\n",
    "    tokens = sample[\"input_tokens\"]\n",
    "\n",
    "    # Convert tokens ‚Üí ids safely\n",
    "    token_ids = [\n",
    "        TOKEN2ID.get(t, TOKEN2ID[\"<UNK>\"])\n",
    "        for t in tokens\n",
    "    ]\n",
    "\n",
    "    # Teacher forcing\n",
    "    input_ids = torch.tensor(token_ids[:-1], dtype=torch.long)\n",
    "    labels = torch.tensor(token_ids[1:], dtype=torch.long)\n",
    "\n",
    "    # üî• IMPORTANT FIX:\n",
    "    # Ignore PAD tokens in loss & metrics\n",
    "    labels[labels == TOKEN2ID[PAD]] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c66850-92dc-4648-820b-89b2f82ffc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Cell 4 ‚Äî Phase-4 Dataset\n",
    "class Phase4JoinDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return prepare_phase4_sample(self.data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0150c7d-981b-4d28-afef-efedfed4ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Cell ‚Äî Phase-4 Collate Function (PAD + MASK)\n",
    "\n",
    "def phase4_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Pads variable-length Phase-4 samples.\n",
    "    Ensures DataLoader can stack tensors safely.\n",
    "    \"\"\"\n",
    "\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "\n",
    "    max_len = max(x.size(0) for x in input_ids)\n",
    "\n",
    "    padded_inputs = []\n",
    "    padded_labels = []\n",
    "\n",
    "    for inp, lab in zip(input_ids, labels):\n",
    "        pad_len = max_len - inp.size(0)\n",
    "\n",
    "        padded_inputs.append(\n",
    "            torch.cat([\n",
    "                inp,\n",
    "                torch.full((pad_len,), TOKEN2ID[PAD], dtype=torch.long)\n",
    "            ])\n",
    "        )\n",
    "\n",
    "        padded_labels.append(\n",
    "            torch.cat([\n",
    "                lab,\n",
    "                torch.full((pad_len,), -100, dtype=torch.long)\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.stack(padded_inputs),\n",
    "        \"labels\": torch.stack(padded_labels)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6be7b2b-8776-4980-90a3-5de501744e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ üîπ Cell 5 ‚Äî DataLoade\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = Phase4JoinDataset(phase4_data)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=phase4_collate_fn   # üî• THIS FIXES THE CRASH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ad13c7d-668a-4d21-ac47-e238b6cbf09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîπ Cell 6 ‚Äî Grammar-Masked Loss (ACTUALLY CORRECT)\n",
    "\n",
    "'''def phase4_loss(logits, input_ids, labels, allowed_token_fn):\n",
    "    \"\"\"\n",
    "    Grammar-constrained loss for Phase-4 JOIN training.\n",
    "\n",
    "    ‚úî Grammar derived from input_ids (decoder history)\n",
    "    ‚úî PAD-only steps skipped\n",
    "    ‚úî No inf / NaN possible\n",
    "    ‚úî Phase-4 safe\n",
    "    \"\"\"\n",
    "\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction=\"sum\")\n",
    "\n",
    "    B, T, V = logits.size()\n",
    "    total_loss = 0.0\n",
    "    valid_steps = 0\n",
    "\n",
    "    for t in range(T):\n",
    "\n",
    "        # skip positions where all labels are ignored\n",
    "        if torch.all(labels[:, t] == -100):\n",
    "            continue\n",
    "\n",
    "        step_logits = logits[:, t, :]   # (B, V)\n",
    "\n",
    "        step_masks = []\n",
    "\n",
    "        for b in range(B):\n",
    "            # üî• USE input_ids, NOT labels\n",
    "            ids = input_ids[b, :t].tolist()\n",
    "            tokens_so_far = [ID2TOKEN[i] for i in ids]\n",
    "\n",
    "            allowed = allowed_token_fn(\n",
    "                tokens_so_far=tokens_so_far,\n",
    "                schema_tables=None,\n",
    "                schema_columns=None\n",
    "            )\n",
    "\n",
    "            if not allowed:\n",
    "                mask = torch.zeros(V, device=logits.device)\n",
    "            else:\n",
    "                mask = torch.full((V,), float(\"-inf\"), device=logits.device)\n",
    "                mask[list(allowed)] = 0.0\n",
    "\n",
    "            step_masks.append(mask)\n",
    "\n",
    "        step_mask = torch.stack(step_masks, dim=0)  # (B, V)\n",
    "        masked_logits = step_logits + step_mask\n",
    "\n",
    "        step_loss = loss_fn(masked_logits, labels[:, t])\n",
    "        total_loss += step_loss\n",
    "        valid_steps += B\n",
    "\n",
    "    return total_loss / max(valid_steps, 1)'''\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def phase4_loss(logits, input_ids, labels, allowed_token_fn):\n",
    "    \"\"\"\n",
    "    Final optimized loss for Phase-4.\n",
    "    Corrects the indexing and ensures stable reduction.\n",
    "    \"\"\"\n",
    "    B, T, V = logits.size()\n",
    "    \n",
    "    # Use a slightly smaller penalty (-1000.0) for better gradient flow\n",
    "    # while still effectively zeroing out the probability.\n",
    "    mask = torch.zeros((B, T, V), device=logits.device)\n",
    "    \n",
    "    for b in range(B):\n",
    "        # We start at t=0 to predict labels[0]\n",
    "        for t in range(T):\n",
    "            if labels[b, t] == -100:\n",
    "                continue\n",
    "            \n",
    "            # üî• CRITICAL FIX: To predict label at index 't', the model \n",
    "            # has seen tokens from 0 up to 't' in teacher forcing.\n",
    "            ids = input_ids[b, :t+1].tolist()\n",
    "            tokens_so_far = [ID2TOKEN.get(i, UNK) for i in ids]\n",
    "            \n",
    "            allowed = allowed_token_fn(\n",
    "                tokens_so_far=tokens_so_far,\n",
    "                schema_tables=None,\n",
    "                schema_columns=None\n",
    "            )\n",
    "            \n",
    "            if allowed:\n",
    "                # Use -1000.0 instead of -1e4 or -1e9 for numerical safety\n",
    "                m = torch.full((V,), -1000.0, device=logits.device)\n",
    "                for token_id in allowed:\n",
    "                    if token_id < V: # Safety check for vocab size\n",
    "                        m[token_id] = 0.0\n",
    "                mask[b, t, :] = m\n",
    "\n",
    "    # Apply mask\n",
    "    masked_logits = logits + mask\n",
    "    \n",
    "    # Flatten: (B*T, V) and (B*T)\n",
    "    # CrossEntropyLoss with ignore_index=-100 handles the mean calculation correctly.\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100, reduction=\"mean\")\n",
    "    \n",
    "    return loss_fn(masked_logits.view(-1, V), labels.view(-1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ec20a9-da98-479a-846c-05196ea88d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üîπ Cell 7 ‚Äî Metric Helpers (NEW)\n",
    "def compute_prf(preds, labels, ignore_index=-100):\n",
    "    preds = preds.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "\n",
    "    mask = labels != ignore_index\n",
    "    preds = preds[mask]\n",
    "    labels = labels[mask]\n",
    "\n",
    "    tp = (preds == labels).sum().item()\n",
    "    fp = (preds != labels).sum().item()\n",
    "    fn = fp  # token-level symmetric\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-9)\n",
    "    recall = tp / (tp + fn + 1e-9)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2382ee0b-42c3-440e-936c-fa6bf89e953b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surgery on layer: embedding.weight\n",
      "Surgery on layer: fc_out.weight\n",
      "Surgery on layer: fc_out.bias\n",
      "‚úÖ Surgery Complete: Phase-3 weights (size 48) adapted to Phase-4 model (size 49)\n"
     ]
    }
   ],
   "source": [
    "# üîπ Cell ‚Äî Load Phase-3 model with Vocab Surgery\n",
    "model = SQLTransformer().to(device)\n",
    "\n",
    "# 1. Load the checkpoint state\n",
    "checkpoint_state = torch.load(PHASE3_CKPT, map_location=device)\n",
    "\n",
    "# 2. Get current model's state dict\n",
    "model_state = model.state_dict()\n",
    "\n",
    "# 3. Identify the layers that changed size\n",
    "# These are the ones causing the \"Size Mismatch\"\n",
    "mismatched_layers = [\"embedding.weight\", \"fc_out.weight\", \"fc_out.bias\"]\n",
    "\n",
    "for name, param in checkpoint_state.items():\n",
    "    if name in mismatched_layers:\n",
    "        print(f\"Surgery on layer: {name}\")\n",
    "        old_weight = param\n",
    "        new_weight = model_state[name]\n",
    "        \n",
    "        # Copy the old weights (0 to 47) into the new weight tensor (0 to 48)\n",
    "        # The 49th index (for <AGG>) will remain randomly initialized\n",
    "        if len(old_weight.shape) > 1: # For Weights (Matrices)\n",
    "            new_weight[:old_weight.shape[0], :] = old_weight\n",
    "        else: # For Biases (Vectors)\n",
    "            new_weight[:old_weight.shape[0]] = old_weight\n",
    "            \n",
    "        model_state[name] = new_weight\n",
    "    else:\n",
    "        # For all other layers (Transformer blocks), just copy directly\n",
    "        model_state[name] = param\n",
    "\n",
    "# 4. Load the modified state dict into the model\n",
    "model.load_state_dict(model_state)\n",
    "\n",
    "print(f\"‚úÖ Surgery Complete: Phase-3 weights (size 48) adapted to Phase-4 model (size 49)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70515f74-8b0b-4d6c-9191-1f70083abec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Grammar Conflicts: 0\n"
     ]
    }
   ],
   "source": [
    "def verify_grammar_with_data(dataset, allowed_fn):\n",
    "    conflicts = 0\n",
    "    for i in range(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        tokens = sample[\"input_tokens\"] # Full sequence from JSON\n",
    "        \n",
    "        for t in range(len(tokens)-1):\n",
    "            so_far = tokens[:t+1]\n",
    "            target = tokens[t+1]\n",
    "            allowed_ids = allowed_fn(so_far)\n",
    "            target_id = TOKEN2ID.get(target)\n",
    "            \n",
    "            if target_id not in allowed_ids:\n",
    "                conflicts += 1\n",
    "                # print(f\"Sample {i} | Error at step {t}: '{target}' is BLOCKED after {so_far[-3:]}\")\n",
    "                # break \n",
    "    print(f\"Total Grammar Conflicts: {conflicts}\")\n",
    "\n",
    "verify_grammar_with_data(phase4_data, get_allowed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee16322b-26d9-4a49-af68-90f897a6840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Avg Loss: 0.1308 | P: 0.5365 | F1: 0.5365\n",
      "Epoch 02 | Avg Loss: 0.0035 | P: 0.6776 | F1: 0.6776\n",
      "Epoch 03 | Avg Loss: 0.0015 | P: 0.7048 | F1: 0.7048\n",
      "Epoch 04 | Avg Loss: 0.0009 | P: 0.7164 | F1: 0.7164\n",
      "Epoch 05 | Avg Loss: 0.0007 | P: 0.7277 | F1: 0.7277\n",
      "Epoch 06 | Avg Loss: 0.0005 | P: 0.7322 | F1: 0.7322\n",
      "Epoch 07 | Avg Loss: 0.0005 | P: 0.7362 | F1: 0.7362\n",
      "Epoch 08 | Avg Loss: 0.0003 | P: 0.7363 | F1: 0.7363\n",
      "Epoch 09 | Avg Loss: 0.0003 | P: 0.7423 | F1: 0.7423\n",
      "Epoch 10 | Avg Loss: 0.0002 | P: 0.7451 | F1: 0.7451\n"
     ]
    }
   ],
   "source": [
    "# üîπ Cell 8 ‚Äî Freeze Phase-1/2/3 (CORRECT)\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if not name.startswith(\"fc_out\"):\n",
    "#         param.requires_grad = False\n",
    "#     else:\n",
    "#         param.requires_grad = True\n",
    "\n",
    "# üîπ Cell 8 ‚Äî Unfreeze more of the model\n",
    "# We unfreeze the last block + the output head so it can learn JOIN context\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layers.1\" in name or \"fc_out\" in name: # Adjust 'layers.1' to your last block index\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "# üîπ Cell 9 ‚Äî Optimizer\n",
    "optimizer = AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=3e-4\n",
    ")\n",
    "\n",
    "# üîπ Cell 10 ‚Äî Improved Training Loop\n",
    "EPOCHS = 10 \n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss, steps = 0.0, 0\n",
    "    total_p, total_r, total_f1 = 0.0, 0.0, 0.0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        logits = model(input_ids)\n",
    "        loss = phase4_loss(logits, input_ids, labels, get_allowed_tokens)\n",
    "        \n",
    "        # Check for NaN\n",
    "        if torch.isnan(loss):\n",
    "            print(\"‚ö†Ô∏è NaN Loss detected! Skipping batch.\")\n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        p, r, f1 = compute_prf(preds, labels)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_p += p\n",
    "        total_r += r\n",
    "        total_f1 += f1\n",
    "        steps += 1\n",
    "\n",
    "    # ‚úÖ REPORT AVERAGE LOSS (total_loss / steps)\n",
    "    avg_loss = total_loss / steps\n",
    "    print(f\"Epoch {epoch+1:02d} | Avg Loss: {avg_loss:.4f} | P: {total_p/steps:.4f} | F1: {total_f1/steps:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9154b-5323-4471-a95b-f12aadc3d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üîπ Cell 9 ‚Äî Optimizer\n",
    "# optimizer = AdamW(\n",
    "#     filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#     lr=3e-4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a67b23-53d3-4c66-ac89-a865787577cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üîπ Cell 10 ‚Äî Phase-4 Training Loop (WITH METRICS)\n",
    "\n",
    "# EPOCHS = 6\n",
    "\n",
    "# model.to(device)\n",
    "# model.train()\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     total_loss = 0.0\n",
    "#     total_p, total_r, total_f1 = 0.0, 0.0, 0.0\n",
    "#     steps = 0\n",
    "\n",
    "#     for batch in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         input_ids = batch[\"input_ids\"].to(device)\n",
    "#         labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#         logits = model(input_ids)\n",
    "\n",
    "#         loss = phase4_loss(\n",
    "#         logits=logits,\n",
    "#         input_ids=input_ids,\n",
    "#         labels=labels,\n",
    "#         allowed_token_fn=get_allowed_tokens\n",
    "#     )\n",
    "\n",
    "#         loss.backward()\n",
    "#         # üîπ Gradient clipping torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # ---- metrics ----\n",
    "#         preds = torch.argmax(logits, dim=-1)\n",
    "#         p, r, f1 = compute_prf(preds, labels)\n",
    "\n",
    "#         total_loss += loss.item()\n",
    "#         total_p += p\n",
    "#         total_r += r\n",
    "#         total_f1 += f1\n",
    "#         steps += 1\n",
    "\n",
    "#     # ---- epoch summary ----\n",
    "#     print(\n",
    "#         f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "#         f\"Loss: {total_loss:.4f} | \"\n",
    "#         f\"P: {total_p/steps:.4f} | \"\n",
    "#         f\"R: {total_r/steps:.4f} | \"\n",
    "#         f\"F1: {total_f1/steps:.4f}\"\n",
    "#     )\n",
    "\n",
    "#     # ---- save checkpoint ----\n",
    "#     ckpt_path = os.path.join(\n",
    "#         CHECKPOINT_DIR,\n",
    "#         f\"phase4_join_epoch_{epoch+1}.pt\"\n",
    "#     )\n",
    "#     torch.save(model.state_dict(), ckpt_path)\n",
    "#     print(f\"üíæ Saved checkpoint ‚Üí {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72628112-9385-4160-9e2d-1f933b9c89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#üîπ Cell 11 ‚Äî Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44d31f-3869-44a4-8137-4be4194d1c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
