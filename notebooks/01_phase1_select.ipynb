{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df5427b2-9e21-4e4b-81e3-bbc00c1f0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 â€” Imports & Config\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models.sql_transformer import SQLTransformer\n",
    "from src.utils import (\n",
    "    tokens_to_ids,\n",
    "    pad_sequence,\n",
    "    create_attention_mask,\n",
    "    set_seed,\n",
    "    get_device\n",
    ")\n",
    "from src.vocab import PAD, TOKEN2ID\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2020b555-2648-4c6d-869e-917b4a8c8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# CONFIG\n",
    "# =====================\n",
    "DATASET_PATH = \"../data/sql_ast/phase1_simple_select.json\"\n",
    "CHECKPOINT_PATH = \"checkpoints/phase1_model.pt\"\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "LR = 1e-3\n",
    "MAX_LEN = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7da88cf-f674-47bd-b949-6c7b8d55ae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 â€” Imports & Config\n",
    "class Phase1Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.data[idx][\"input_tokens\"]\n",
    "\n",
    "        ids = tokens_to_ids(tokens)\n",
    "        ids = pad_sequence(ids, MAX_LEN, TOKEN2ID[PAD])\n",
    "        mask = create_attention_mask(ids, TOKEN2ID[PAD])\n",
    "\n",
    "        return (\n",
    "            torch.tensor(ids, dtype=torch.long),\n",
    "            torch.tensor(mask, dtype=torch.long)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b52f7d16-9658-4965-a105-703dea0f259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Cell 3 â€” Metrics (Precision / Recall / F1)\n",
    "def compute_prf(preds, labels, pad_id):\n",
    "    tp = fp = fn = 0\n",
    "\n",
    "    for p_seq, l_seq in zip(preds, labels):\n",
    "        for p, l in zip(p_seq, l_seq):\n",
    "            if l == pad_id:\n",
    "                continue\n",
    "            if p == l:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "                fn += 1\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-9)\n",
    "    recall = tp / (tp + fn + 1e-9)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e15e85af-0ff3-4044-8ef3-49e2c1787b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¹ Cell 4 â€” Setup (Device, DataLoader, Model)\n",
    "set_seed(42)\n",
    "device = get_device()\n",
    "\n",
    "dataset = Phase1Dataset(DATASET_PATH)\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = SQLTransformer().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TOKEN2ID[PAD])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00c73a06-031e-4694-a976-de3657f1284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Loss: 1.9022 | P: 0.6464 | R: 0.6464 | F1: 0.6464\n",
      "ðŸ’¾ Checkpoint saved\n",
      "Epoch 02 | Loss: 0.2598 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "ðŸ’¾ Checkpoint saved\n",
      "Epoch 03 | Loss: 0.0931 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 04 | Loss: 0.0553 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 05 | Loss: 0.0384 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 06 | Loss: 0.0291 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 07 | Loss: 0.0230 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 08 | Loss: 0.0190 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 09 | Loss: 0.0162 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 10 | Loss: 0.0143 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 11 | Loss: 0.0127 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 12 | Loss: 0.0114 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 13 | Loss: 0.0105 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 14 | Loss: 0.0096 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 15 | Loss: 0.0090 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 16 | Loss: 0.0084 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 17 | Loss: 0.0079 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 18 | Loss: 0.0075 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 19 | Loss: 0.0071 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n",
      "Epoch 20 | Loss: 0.0067 | P: 1.0000 | R: 1.0000 | F1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”¹ Cell 5 â€” Training Loop (Notebook-Safe)\n",
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for input_ids, attention_mask in loader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        # Teacher forcing\n",
    "        logits = logits[:, :-1, :]\n",
    "        labels = input_ids[:, 1:]\n",
    "\n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            labels.reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        all_preds.extend(preds.cpu().tolist())\n",
    "        all_labels.extend(labels.cpu().tolist())\n",
    "\n",
    "    precision, recall, f1 = compute_prf(\n",
    "        all_preds,\n",
    "        all_labels,\n",
    "        pad_id=TOKEN2ID[PAD]\n",
    "    )\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Loss: {avg_loss:.4f} | \"\n",
    "        f\"P: {precision:.4f} | \"\n",
    "        f\"R: {recall:.4f} | \"\n",
    "        f\"F1: {f1:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Save best checkpoint\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        torch.save(model.state_dict(), CHECKPOINT_PATH)\n",
    "        print(\"ðŸ’¾ Checkpoint saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b20b0534-2d71-4eb7-8083-7ba9b612003d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SQLTransformer(\n",
       "  (embedding): Embedding(48, 128, padding_idx=0)\n",
       "  (pos_embedding): Embedding(512, 128)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_out): Linear(in_features=128, out_features=48, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ðŸ”¹ Cell 6 â€” Load Checkpoint Later (for Phase-2)\n",
    "model = SQLTransformer().to(device)\n",
    "model.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=device))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d16554-f8c0-48b0-88bb-9516ad730671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
